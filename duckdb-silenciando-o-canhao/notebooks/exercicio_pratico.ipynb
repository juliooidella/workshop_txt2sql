{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66e69b46",
   "metadata": {},
   "source": [
    "## Parte 0: Gerando o Cen√°rio (O Problema)\n",
    "Vamos gerar um arquivo CSV com 1 a 5 milh√µes de linhas para simular o \"peso\" de carregar dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac0d4729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gerando CSV de vendas... (Isso pode levar alguns segundos)\n",
      "CSV gerado com sucesso em ../data/vendas_big.csv!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Garantir que a pasta data existe\n",
    "os.makedirs('../data', exist_ok=True)\n",
    "\n",
    "# Gerando dados dummy de Vendas (simulando a tabela do slide 4)\n",
    "print(\"Gerando CSV de vendas... (Isso pode levar alguns segundos)\")\n",
    "df = pd.DataFrame({\n",
    "    'id_pedido': range(1, 1000001),\n",
    "    'data': pd.date_range(start='2023-01-01', periods=1000000, freq='s'),\n",
    "    'regiao': np.random.choice(['Norte', 'Sul', 'Leste', 'Oeste'], 1000000),\n",
    "    'produto': np.random.choice(['Mouse', 'Teclado', 'Monitor', 'Cabo'], 1000000),\n",
    "    'valor': np.random.uniform(10, 500, 1000000).round(2)\n",
    "})\n",
    "df.to_csv('../data/vendas_big.csv', index=False)\n",
    "print(\"CSV gerado com sucesso em ../data/vendas_big.csv!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1442aa6e",
   "metadata": {},
   "source": [
    "## Parte 1: O \"Canh√£o\" (Abordagem Pandas Tradicional)\n",
    "Aqui demonstramos a abordagem criticada, onde carregamos o arquivo inteiro para a mem√≥ria RAM s√≥ para fazer uma agrega√ß√£o simples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d95b747b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando CSV com Pandas...\n",
      "Tempo Pandas: 0.5987 segundos\n",
      "regiao\n",
      "Leste    63937663.84\n",
      "Norte    63728638.70\n",
      "Oeste    63685725.54\n",
      "Sul      63820057.05\n",
      "Name: valor, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# O jeito \"Sandbox Pesado\"\n",
    "start = time.time()\n",
    "\n",
    "# 1. Carrega tudo para mem√≥ria (Gargalo de I/O e RAM)\n",
    "print(\"Carregando CSV com Pandas...\")\n",
    "df_pandas = pd.read_csv('../data/vendas_big.csv')\n",
    "\n",
    "# 2. Processa l√≥gica pythonica\n",
    "resultado = df_pandas.groupby('regiao')['valor'].sum()\n",
    "\n",
    "end = time.time()\n",
    "print(f\"Tempo Pandas: {end - start:.4f} segundos\")\n",
    "print(resultado)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0185319d",
   "metadata": {},
   "source": [
    "> **Nota:** Observe o tempo gasto. Se o arquivo tivesse 10GB, sua m√°quina provavelmente travaria ou o processo seria morto por falta de mem√≥ria (OOM)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd321fb4",
   "metadata": {},
   "source": [
    "## Parte 2: A \"Ferramenta Certa\" (DuckDB em CSV)\n",
    "Agora usamos o DuckDB lendo o CSV diretamente. Ele √© um motor OLAP *in-process* que consegue executar SQL em arquivos sem carreg√°-los totalmente na RAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fec0d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
      "‚îÇ regiao  ‚îÇ    total_vendas    ‚îÇ\n",
      "‚îÇ varchar ‚îÇ       double       ‚îÇ\n",
      "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
      "‚îÇ Sul     ‚îÇ  63820057.05000006 ‚îÇ\n",
      "‚îÇ Oeste   ‚îÇ 63685725.539999776 ‚îÇ\n",
      "‚îÇ Norte   ‚îÇ   63728638.7000001 ‚îÇ\n",
      "‚îÇ Leste   ‚îÇ  63937663.83999974 ‚îÇ\n",
      "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
      "\n",
      "Tempo DuckDB (CSV direto): 0.1300 segundos\n"
     ]
    }
   ],
   "source": [
    "import duckdb\n",
    "\n",
    "# O jeito \"DuckDB\" - SQL direto no arquivo\n",
    "start = time.time()\n",
    "\n",
    "# Note que usamos o arquivo CSV como se fosse uma tabela\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    regiao, \n",
    "    SUM(valor) as total_vendas\n",
    "FROM '../data/vendas_big.csv'\n",
    "GROUP BY regiao\n",
    "\"\"\"\n",
    "duckdb.sql(query).show()\n",
    "\n",
    "end = time.time()\n",
    "print(f\"Tempo DuckDB (CSV direto): {end - start:.4f} segundos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd933d84",
   "metadata": {},
   "source": [
    "## Parte 3: Otimiza√ß√£o da Arquitetura (Parquet)\n",
    "Para atingir a performance ideal para Agentes de IA (que precisam de respostas em sub-segundos), convertemos os dados para **Parquet** (formato colunar)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7760c44d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convertendo para Parquet...\n",
      "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
      "‚îÇ regiao  ‚îÇ     sum(valor)     ‚îÇ\n",
      "‚îÇ varchar ‚îÇ       double       ‚îÇ\n",
      "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
      "‚îÇ Leste   ‚îÇ 63937663.839999765 ‚îÇ\n",
      "‚îÇ Norte   ‚îÇ  63728638.70000008 ‚îÇ\n",
      "‚îÇ Oeste   ‚îÇ  63685725.53999995 ‚îÇ\n",
      "‚îÇ Sul     ‚îÇ  63820057.05000003 ‚îÇ\n",
      "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
      "\n",
      "Tempo DuckDB (Parquet): 0.0045 segundos\n"
     ]
    }
   ],
   "source": [
    "# 1. Converter CSV para Parquet (Simulando a etapa de Ingest√£o)\n",
    "print(\"Convertendo para Parquet...\")\n",
    "duckdb.sql(\"COPY (SELECT * FROM '../data/vendas_big.csv') TO '../data/vendas.parquet' (FORMAT PARQUET)\")\n",
    "\n",
    "# 2. Consultar no Parquet\n",
    "start = time.time()\n",
    "duckdb.sql(\"SELECT regiao, SUM(valor) FROM '../data/vendas.parquet' GROUP BY regiao\").show()\n",
    "end = time.time()\n",
    "\n",
    "print(f\"Tempo DuckDB (Parquet): {end - start:.4f} segundos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2f8d7d",
   "metadata": {},
   "source": [
    "## Parte 4: Materializando o Banco e Simulando IA\n",
    "Muitos acham que a IA faz m√°gica. Aqui vamos mostrar a engenharia por tr√°s: **Function Calling**.\n",
    "\n",
    "Primeiro, vamos criar um arquivo de banco de dados persistente (`.duckdb`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc1484cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Materializando banco de dados DuckDB persistente...\n",
      "Banco '../data/vendas.duckdb' criado com sucesso!\n",
      "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
      "‚îÇ column_name ‚îÇ column_type ‚îÇ  null   ‚îÇ   key   ‚îÇ default ‚îÇ  extra  ‚îÇ\n",
      "‚îÇ   varchar   ‚îÇ   varchar   ‚îÇ varchar ‚îÇ varchar ‚îÇ varchar ‚îÇ varchar ‚îÇ\n",
      "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
      "‚îÇ id_pedido   ‚îÇ BIGINT      ‚îÇ YES     ‚îÇ NULL    ‚îÇ NULL    ‚îÇ NULL    ‚îÇ\n",
      "‚îÇ data        ‚îÇ TIMESTAMP   ‚îÇ YES     ‚îÇ NULL    ‚îÇ NULL    ‚îÇ NULL    ‚îÇ\n",
      "‚îÇ regiao      ‚îÇ VARCHAR     ‚îÇ YES     ‚îÇ NULL    ‚îÇ NULL    ‚îÇ NULL    ‚îÇ\n",
      "‚îÇ produto     ‚îÇ VARCHAR     ‚îÇ YES     ‚îÇ NULL    ‚îÇ NULL    ‚îÇ NULL    ‚îÇ\n",
      "‚îÇ valor       ‚îÇ DOUBLE      ‚îÇ YES     ‚îÇ NULL    ‚îÇ NULL    ‚îÇ NULL    ‚îÇ\n",
      "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Materializando banco de dados DuckDB persistente...\")\n",
    "\n",
    "# Conecta (ou cria) o arquivo f√≠sico\n",
    "con = duckdb.connect('../data/vendas.duckdb')\n",
    "\n",
    "# Cria a tabela 'vendas' dentro do arquivo .duckdb a partir do Parquet\n",
    "con.sql(\"\"\"\n",
    "    CREATE OR REPLACE TABLE vendas AS \n",
    "    SELECT * FROM '../data/vendas.parquet'\n",
    "\"\"\")\n",
    "\n",
    "print(\"Banco '../data/vendas.duckdb' criado com sucesso!\")\n",
    "con.sql(\"DESCRIBE vendas\").show()\n",
    "\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7243e63",
   "metadata": {},
   "source": [
    "### O \"Truque\" da M√°gica: Simulando Function Calling\n",
    "Vamos simular o fluxo: `Usu√°rio -> LLM (Mock) -> SQL -> DuckDB`.\n",
    "A IA n√£o executa o c√≥digo, ela apenas gera o SQL (Function Call) que nosso motor determin√≠stico executa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d471131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Contexto do Sistema ---\n",
      "\n",
      "Tabela: vendas\n",
      "Colunas: \n",
      "- data (TIMESTAMP)\n",
      "- regiao (STRING): 'Norte', 'Sul', 'Leste', 'Oeste'\n",
      "- produto (STRING)\n",
      "- valor (FLOAT)\n",
      "\n",
      "\n",
      "ü§ñ AI Recebeu: 'Qual o total de vendas na regi√£o Norte?'\n",
      "ü§ñ AI Pensando... (Gerando SQL baseado no Schema)\n",
      "üì© AI Sugeriu Chamada de Fun√ß√£o: {\n",
      "  \"function_name\": \"executar_sql_analitico\",\n",
      "  \"arguments\": {\n",
      "    \"sql_query\": \"SELECT SUM(valor) as total FROM vendas WHERE regiao = 'Norte'\",\n",
      "    \"explicacao\": \"Calculando a soma da coluna valor filtrando pela regi\\u00e3o Norte.\"\n",
      "  }\n",
      "}\n",
      "‚öôÔ∏è  Executando no DuckDB: SELECT SUM(valor) as total FROM vendas WHERE regiao = 'Norte'\n",
      "\n",
      "üìä Resultado Final (Vindo do DuckDB):\n",
      "        total\n",
      "0  63728638.7\n",
      "\n",
      "üí° Explica√ß√£o da IA: Calculando a soma da coluna valor filtrando pela regi√£o Norte.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 1. O \"Prompt de Sistema\" (O que enviamos para a IA)\n",
    "# ---------------------------------------------------------\n",
    "schema_info = \"\"\"\n",
    "Tabela: vendas\n",
    "Colunas: \n",
    "- data (TIMESTAMP)\n",
    "- regiao (STRING): 'Norte', 'Sul', 'Leste', 'Oeste'\n",
    "- produto (STRING)\n",
    "- valor (FLOAT)\n",
    "\"\"\"\n",
    "\n",
    "print(f\"--- Contexto do Sistema ---\\n{schema_info}\\n\")\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 2. A \"M√°gica\" Simulada (Mock do LLM)\n",
    "# ---------------------------------------------------------\n",
    "def mock_llm_function_call(user_question):\n",
    "    \"\"\"\n",
    "    Simula um LLM recebendo uma pergunta e decidindo qual SQL gerar.\n",
    "    Na vida real, aqui seria uma chamada para openai.chat.completions.create\n",
    "    \"\"\"\n",
    "    print(f\"ü§ñ AI Recebeu: '{user_question}'\")\n",
    "    print(\"ü§ñ AI Pensando... (Gerando SQL baseado no Schema)\")\n",
    "    \n",
    "    # MOCK: Vamos fingir que a IA gerou isso deterministicamente\n",
    "    if \"total\" in user_question.lower() and \"norte\" in user_question.lower():\n",
    "        # A IA retorna um JSON estruturado, n√£o apenas texto solto\n",
    "        return {\n",
    "            \"function_name\": \"executar_sql_analitico\",\n",
    "            \"arguments\": {\n",
    "                \"sql_query\": \"SELECT SUM(valor) as total FROM vendas WHERE regiao = 'Norte'\",\n",
    "                \"explicacao\": \"Calculando a soma da coluna valor filtrando pela regi√£o Norte.\"\n",
    "            }\n",
    "        }\n",
    "    elif \"top\" in user_question.lower() and \"produtos\" in user_question.lower():\n",
    "        return {\n",
    "            \"function_name\": \"executar_sql_analitico\",\n",
    "            \"arguments\": {\n",
    "                \"sql_query\": \"SELECT produto, COUNT(*) as qtd FROM vendas GROUP BY produto ORDER BY qtd DESC LIMIT 3\",\n",
    "                \"explicacao\": \"Agrupando por produto e ordenando por contagem decrescente.\"\n",
    "            }\n",
    "        }\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 3. A Fun√ß√£o Determin√≠stica (O Canh√£o Silenciado)\n",
    "# ---------------------------------------------------------\n",
    "def executar_sql_analitico(sql_query):\n",
    "    \"\"\"\n",
    "    Esta √© a ferramenta que a IA decidiu usar.\n",
    "    Ela roda em ambiente controlado (DuckDB), isolado e seguro.\n",
    "    \"\"\"\n",
    "    print(f\"‚öôÔ∏è  Executando no DuckDB: {sql_query}\")\n",
    "    \n",
    "    # Conecta no banco persistente que criamos\n",
    "    con = duckdb.connect('../data/vendas.duckdb')\n",
    "    \n",
    "    try:\n",
    "        df_resultado = con.sql(sql_query).df()\n",
    "        return df_resultado\n",
    "    except Exception as e:\n",
    "        return f\"Erro no SQL: {e}\"\n",
    "    finally:\n",
    "        con.close()\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 4. Orquestra√ß√£o (O Loop do Agente)\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "# Pergunta do Usu√°rio\n",
    "pergunta = \"Qual o total de vendas na regi√£o Norte?\"\n",
    "\n",
    "# Passo A: LLM decide o que fazer\n",
    "resposta_ai = mock_llm_function_call(pergunta)\n",
    "\n",
    "if resposta_ai:\n",
    "    print(f\"üì© AI Sugeriu Chamada de Fun√ß√£o: {json.dumps(resposta_ai, indent=2)}\")\n",
    "    \n",
    "    # Passo B: Sistema executa a ferramenta (Function Calling)\n",
    "    nome_funcao = resposta_ai['function_name']\n",
    "    args = resposta_ai['arguments']\n",
    "    \n",
    "    if nome_funcao == \"executar_sql_analitico\":\n",
    "        resultado_real = executar_sql_analitico(args['sql_query'])\n",
    "        \n",
    "        print(\"\\nüìä Resultado Final (Vindo do DuckDB):\")\n",
    "        print(resultado_real)\n",
    "        print(f\"\\nüí° Explica√ß√£o da IA: {args['explicacao']}\")\n",
    "else:\n",
    "    print(\"AI n√£o entendeu a pergunta.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6959ebe5",
   "metadata": {},
   "source": [
    "## Parte 5: Duelo de Verbosidade (Pandas vs SQL)\n",
    "Visualmente, qual c√≥digo √© mais f√°cil de manter e menos propenso a erros?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d481708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- DUELO DE VERBOSIDADE: PANDAS vs SQL ---\n",
      "\n",
      "[Pandas] Linhas de C√≥digo: 18\n",
      "[DuckDB] Linhas de C√≥digo: 11\n",
      "\n",
      "--- Resultado Visual ---\n",
      "Pandas exige que voc√™ explique 'COMO' fazer (ler, converter, mascarar, filtrar).\n",
      "SQL permite que voc√™ diga apenas 'O QUE' voc√™ quer.\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "\n",
    "print(\"--- DUELO DE VERBOSIDADE: PANDAS vs SQL ---\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# DESAFIO: \"Calcule a m√©dia de vendas de 'Teclado' em Junho/2023\"\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "def abordagem_sandbox_pandas():\n",
    "    # 1. Carregar (Overhead de I/O e Parsing)\n",
    "    # Precisamos definir parse_dates para n√£o falhar na l√≥gica temporal\n",
    "    df = pd.read_csv('../data/vendas_big.csv', parse_dates=['data'])\n",
    "    \n",
    "    # 2. Filtrar Produto (L√≥gica Imperativa)\n",
    "    mask_produto = df['produto'] == 'Teclado'\n",
    "    \n",
    "    # 3. Filtrar Data (Mais l√≥gica imperativa)\n",
    "    mask_data = (df['data'].dt.year == 2023) & (df['data'].dt.month == 6)\n",
    "    \n",
    "    # 4. Aplicar Filtros\n",
    "    df_filtrado = df[mask_produto & mask_data]\n",
    "    \n",
    "    # 5. Calcular e Retornar\n",
    "    if len(df_filtrado) == 0:\n",
    "        return 0\n",
    "    return df_filtrado['valor'].mean()\n",
    "\n",
    "def abordagem_duckdb_sql():\n",
    "    # 1. Declarar a Inten√ß√£o (L√≥gica Declarativa)\n",
    "    # O motor resolve o parsing de data e leitura otimizada sozinho\n",
    "    query = \"\"\"\n",
    "        SELECT AVG(valor) \n",
    "        FROM '../data/vendas_big.csv' \n",
    "        WHERE produto = 'Teclado' \n",
    "          AND year(data) = 2023 \n",
    "          AND month(data) = 6\n",
    "    \"\"\"\n",
    "    return duckdb.sql(query).fetchone()[0]\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Comparativo Visual\n",
    "# ---------------------------------------------------------\n",
    "cod_pandas = inspect.getsource(abordagem_sandbox_pandas)\n",
    "cod_duck = inspect.getsource(abordagem_duckdb_sql)\n",
    "\n",
    "print(f\"\\n[Pandas] Linhas de C√≥digo: {len(cod_pandas.splitlines())}\")\n",
    "print(f\"[DuckDB] Linhas de C√≥digo: {len(cod_duck.splitlines())}\")\n",
    "\n",
    "print(\"\\n--- Resultado Visual ---\")\n",
    "print(\"Pandas exige que voc√™ explique 'COMO' fazer (ler, converter, mascarar, filtrar).\")\n",
    "print(\"SQL permite que voc√™ diga apenas 'O QUE' voc√™ quer.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51827a33",
   "metadata": {},
   "source": [
    "## Parte 6: O Duelo dos Agentes (O que a IA envia)\n",
    "\n",
    "Al√©m da performance de execu√ß√£o, existe o **custo cognitivo e de tokens** para o Agente.\n",
    "\n",
    "Abaixo, comparamos o que um Agente precisa \"pensar\" e enviar para a ferramenta em cada arquitetura.\n",
    "\n",
    "### üî¥ Abordagem 1: Sandbox Python (O \"Canh√£o\")\n",
    "O agente precisa atuar como um Engenheiro de Dados completo: importando bibliotecas, tratando erros de tipagem, lidando com I/O e l√≥gica imperativa.\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"function\": \"executar_codigo_python\",\n",
    "  \"arguments\": {\n",
    "    \"codigo\": \"import pandas as pd\\n\\n# 1. Tenta carregar CSVs gigantes para a RAM\\nfluxo_caixa = pd.read_csv('/mnt/data/fluxo_caixa.csv', sep=';')\\n\\n# 2. Tenta corrigir tipagem manualmente (Lento e propenso a erro)\\nfor col in fluxo_caixa.columns:\\n    if fluxo_caixa[col].dtype == 'object':\\n        fluxo_caixa[col] = fluxo_caixa[col].str.replace('.', '').str.replace(',', '.').astype(float)\\n\\n# 3. L√≥gica de Neg√≥cio Imperativa (Recriando a roda)\\nfluxo_caixa['DTEMISSAO'] = pd.to_datetime(fluxo_caixa['DTEMISSAO'], dayfirst=True)\\nfluxo_caixa['inadimplente'] = (fluxo_caixa['DIASATRASO'] > 0) & (~fluxo_caixa['QUITADA'].isin(['S','B']))\\n\\n# 4. Agrega√ß√µes manuais\\ntotal_receber = fluxo_caixa[fluxo_caixa['ORIGEM'] == 'RECEBER']['SALDO'].sum()\\n\\nprint(total_receber)\"\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "**Riscos:**\n",
    "*   `NameError` / `SyntaxError` (O agente erra c√≥digo).\n",
    "*   `OutOfMemory` (O agente trava o container).\n",
    "*   Alto consumo de tokens (Prompt gigante).\n",
    "\n",
    "---\n",
    "\n",
    "### üü¢ Abordagem 2: SQL + DuckDB (O \"Bisturi\")\n",
    "O agente atua como um Analista S√™nior: ele apenas declara a inten√ß√£o (SQL) e deixa o motor otimizado resolver o \"como\".\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"function\": \"executar_sql_analitico\",\n",
    "  \"arguments\": {\n",
    "    \"sql_query\": \"SELECT SUM(SALDO) as total_receber FROM fluxo_caixa WHERE ORIGEM = 'RECEBER'\",\n",
    "    \"explicacao\": \"Calculando total a receber diretamente da base.\"\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "**Vantagens:**\n",
    "*   **Zero Data Transfer:** O agente n√£o recebe dados brutos, apenas a resposta.\n",
    "*   **Robustez:** Tipagem e leitura s√£o resolvidos pelo Schema do banco.\n",
    "*   **Efici√™ncia:** Prompt min√∫sculo e execu√ß√£o em milissegundos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
